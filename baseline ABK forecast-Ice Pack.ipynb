{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8177ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pmdarima.arima import auto_arima\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "filename = 'C:\\Bee Temp Data\\C294_w_Env.csv'\n",
    "\n",
    "\n",
    "data = pd.read_csv(filename)\n",
    "\n",
    "input_cycle = 7 #how manys days to be used as input?\n",
    "output_cycle = 14 #how manys days to be forecasted ahead?\n",
    "daily_data_points = 24 #data points per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ca4e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    current_date = (datetime.datetime.strptime(str(data['Date'].values[i]), \"%m/%d/%Y\")).date()\n",
    "    current_time = datetime.datetime.strptime(str(data['Time'].values[i]), \"%H:%M:%S\").time()\n",
    "    current_datetime = datetime.datetime.combine(current_date,current_time)\n",
    "    data['DateTime'][i] = datetime.datetime.strptime(str(current_datetime), \"%Y-%m-%d %H:%M:%S\")\n",
    "    data['Date'][i] = data['DateTime'][i].date()\n",
    "    data['Time'][i] = data['DateTime'][i].time()\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a8cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ARX_forecast():\n",
    "    forecast_ARX = np.array([[],[],[],[],[],[],[],[]]).reshape(-1,8)\n",
    "    id_s = 0\n",
    "    for i in range(0,int(len(data)/daily_data_points)-input_cycle-output_cycle+1):\n",
    "        print(i)\n",
    "        d_in =  data[i*daily_data_points:(i+input_cycle+output_cycle)*daily_data_points] #whole dataset -> input_cycle+output_cycle\n",
    "        data_in = d_in[0:input_cycle*daily_data_points]['Temp'] #input core temperature data\n",
    "        \n",
    "        exogenous_train = pd.DataFrame(d_in[0:input_cycle*daily_data_points]) #input exogenous data\n",
    "        train_ext_temp = exogenous_train['Air Temp'] - np.mean(exogenous_train['Air Temp']) #removing offset/trend\n",
    "        train_solar = exogenous_train['Sol Rad'] - np.mean(exogenous_train['Sol Rad'])\n",
    "        train_ice = exogenous_train['P'] \n",
    "        exogenous_all_var = np.concatenate((np.linspace(0,len(exogenous_train['Air Temp'])-1,num=len(exogenous_train['Air Temp']),dtype = np.uint8).reshape(-1,1),\n",
    "                                            np.array(train_ext_temp).reshape(-1,1)),axis = 1).reshape(len(exogenous_train['Air Temp']),-1)\n",
    "        exogenous_all_var = np.concatenate((exogenous_all_var, np.array(train_solar).reshape(-1,1)),axis = 1).reshape(len(exogenous_train['Sol Rad']),-1)\n",
    "        exogenous_all_var = np.concatenate((exogenous_all_var, np.array(train_ice).reshape(-1,1)),axis = 1).reshape(len(exogenous_train['P']),-1)\n",
    "        model = auto_arima( data_in, X = exogenous_all_var, start_p = 1, max_p = 1,\n",
    "                            d = 0, max_d = 0,\n",
    "                            start_q = 0, max_q = 0, information_criterion='aic')\n",
    "        model.fit(data_in, X = exogenous_all_var)\n",
    "\n",
    "        last_date_input = d_in[0:input_cycle*daily_data_points]['Date'].values[-1]\n",
    "                \n",
    "        forecast_whole = np.array([[],[],[],[]]).reshape(-1,4)\n",
    "\n",
    "        forecast_data = d_in[input_cycle*daily_data_points:(input_cycle+output_cycle)*daily_data_points]\n",
    "        forecast_data = forecast_data.reset_index() \n",
    "        \n",
    "        for p in range(len(forecast_data)):\n",
    "            forecast_data_date = datetime.datetime.strptime(str(forecast_data['Date'].values[p]),  \"%Y-%m-%d\").date() \n",
    "            forecast_data_time = datetime.datetime.strptime(str(forecast_data['Time'].values[p]), \"%H:%M:%S\").time()\n",
    "            forecast_data['DateTime'][p] = str(datetime.datetime.combine(forecast_data_date,forecast_data_time))\n",
    "    \n",
    "        #print('forecast_data',forecast_data)\n",
    "        current_date = np.array([[],[],[]]).reshape(-1,3)\n",
    "        for p in range(output_cycle*daily_data_points):\n",
    "            current_date_forecast = (datetime.datetime.strptime(str(last_date_input), \"%Y-%m-%d\") + datetime.timedelta(days=int(p/daily_data_points) + 1)).date()\n",
    "            current_time_forecast = datetime.datetime.strptime(str(forecast_data['Time'].values[p]), \"%H:%M:%S\").time()\n",
    "            current_datetime_forecast = datetime.datetime.combine(current_date_forecast,current_time_forecast)\n",
    "            current_date = np.concatenate((current_date, np.array([str(current_date_forecast),\n",
    "                                                                    str(current_time_forecast),\n",
    "                                                                    str(current_datetime_forecast)]).reshape(3,-1).T))\n",
    "        current_date = pd.DataFrame(current_date, columns = ['Date','Time','DateTime'])\n",
    "        #print('current_data',current_date)            \n",
    "        forecast_data = forecast_data.merge(current_date, how = 'outer', left_on = 'DateTime', right_on = 'DateTime')\n",
    "        #print('forecast_data_merged_first',forecast_data)\n",
    "        forecast_data = forecast_data[~np.isnan(forecast_data['Temp'].values)]\n",
    "        forecast_data = forecast_data[~pd.isnull(forecast_data['Date_y'].values)]\n",
    "        #print('forecast_data_merged',forecast_data)\n",
    "        forecast_data_partial = forecast_data[['Date_y', 'Time_y', 'DateTime', 'Air Temp', 'Sol Rad', 'Temp']]\n",
    "        forecast_data_partial = forecast_data_partial.rename(columns={\"Date_y\": \"Date\", \"Time_y\": \"Time\"})\n",
    "\n",
    "        exogenous_forecast = pd.DataFrame(forecast_data_partial)\n",
    "        forecast_ext_temp = exogenous_forecast['Air Temp'] - np.mean(exogenous_forecast['Air Temp'])\n",
    "        forecast_solar = exogenous_forecast['Sol Rad'] - np.mean(exogenous_forecast['Sol Rad'])\n",
    "        forecast_ice = [0]*len(forecast_solar)\n",
    "        exogenous_all_var_forecast = np.concatenate((np.linspace(0,len(exogenous_forecast['Air Temp'])-1,num=len(exogenous_forecast['Air Temp']),dtype = np.uint8).reshape(-1,1),\n",
    "                                            np.array(forecast_ext_temp).reshape(-1,1)),axis = 1).reshape(len(exogenous_forecast['Air Temp']),-1)\n",
    "        exogenous_all_var_forecast = np.concatenate((exogenous_all_var_forecast, np.array(forecast_solar).reshape(-1,1)),axis = 1).reshape(len(exogenous_forecast['Sol Rad']),-1)\n",
    "        exogenous_all_var_forecast = np.concatenate((exogenous_all_var_forecast, np.array(forecast_ice).reshape(-1,1)),axis = 1).reshape(len(exogenous_forecast['Sol Rad']),-1)\n",
    "        \n",
    "        forecast = model.predict(len(exogenous_forecast['Air Temp']), X = exogenous_all_var_forecast)\n",
    "        #data_in= np.concatenate((data_in,forecast))\n",
    "        id_no = [id_s]*len(forecast)\n",
    "        id_s = id_s + 1\n",
    "        forecast_ARX = np.concatenate((forecast_ARX, np.array([forecast_data_partial['Date'].values, \n",
    "                                                               forecast_data_partial['Time'].values,\n",
    "                                                               forecast_data_partial['DateTime'].values,  \n",
    "                                                               forecast_data_partial['Air Temp'].values,         \n",
    "                                                               forecast_data_partial['Sol Rad'].values,\n",
    "                                                               forecast_data_partial['Temp'].values,\n",
    "                                                               forecast,\n",
    "                                                               np.array(id_no)]).reshape(8,-1).T))\n",
    "        plt.plot(range(len(forecast_data_partial['Temp'].values)), forecast_data_partial['Temp'].values, label = 'Actual')\n",
    "        plt.plot(range(len(forecast_data_partial['Temp'].values)), forecast, label = 'forecast')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    forecast_ARX = pd.DataFrame(forecast_ARX, columns = ['Date', 'Time', 'DateTime', 'Air Temp', 'Sol Rad',\n",
    "                                                        'Temp_Actual', 'ARX', 'id_no'])\n",
    "    forecast_ARX['ARX error_2'] = (forecast_ARX['Temp_Actual'] - forecast_ARX['ARX'])**2\n",
    "    return forecast_ARX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac456fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_ARX = ARX_forecast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b7e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Seasonal_ARX_forecast():\n",
    "    forecast_sARX = np.array([[],[],[],[],[],[],[],[]]).reshape(-1,8)\n",
    "    id_s = 0\n",
    "    for i in range(0,int(len(data)/daily_data_points)-input_cycle-output_cycle+1):\n",
    "        print(i)\n",
    "        d_in =  data[i*daily_data_points:(i+input_cycle+output_cycle)*daily_data_points] #whole dataset -> input_cycle+output_cycle\n",
    "        data_in = d_in[0:input_cycle*daily_data_points]['Temp'] #input core temperature data\n",
    "\n",
    "        exogenous_train = pd.DataFrame(d_in[0:len(data_in)]) #input exogenous data\n",
    "        train_ext_temp = exogenous_train['Air Temp'] - np.mean(exogenous_train['Air Temp']) #removing offset/trend\n",
    "        train_solar = exogenous_train['Sol Rad'] - np.mean(exogenous_train['Sol Rad'])\n",
    "        train_ice = exogenous_train['P'] \n",
    "        exogenous_all_var = np.concatenate((np.linspace(0,len(exogenous_train['Air Temp'])-1,num=len(exogenous_train['Air Temp']),dtype = np.uint8).reshape(-1,1),\n",
    "                                            np.array(train_ext_temp).reshape(-1,1)),axis = 1).reshape(len(exogenous_train['Air Temp']),-1)\n",
    "        exogenous_all_var = np.concatenate((exogenous_all_var, np.array(train_solar).reshape(-1,1)),axis = 1).reshape(len(exogenous_train['Sol Rad']),-1)\n",
    "        exogenous_all_var = np.concatenate((exogenous_all_var, np.array(train_ice).reshape(-1,1)),axis = 1).reshape(len(exogenous_train['P']),-1)\n",
    "        model = auto_arima( data_in, X = exogenous_all_var, start_p = 1, max_p = 1,\n",
    "                            d = 0, max_d = 0,\n",
    "                            start_q = 0, max_q = 0, \n",
    "                            max_P = 1, D = 0, max_D = 0, start_Q = 0, max_Q = 0,\n",
    "                            m = 24, information_criterion='aic')\n",
    "        model.fit(data_in, X = exogenous_all_var)\n",
    "        last_date_input = d_in[0:input_cycle*daily_data_points]['Date'].values[-1]\n",
    "                \n",
    "        forecast_whole = np.array([[],[],[],[]]).reshape(-1,4)\n",
    "\n",
    "        forecast_data = d_in[input_cycle*daily_data_points:(input_cycle+output_cycle)*daily_data_points]\n",
    "        forecast_data = forecast_data.reset_index() \n",
    "        \n",
    "        for p in range(len(forecast_data)):\n",
    "            forecast_data_date = datetime.datetime.strptime(str(forecast_data['Date'].values[p]),  \"%Y-%m-%d\").date() \n",
    "            forecast_data_time = datetime.datetime.strptime(str(forecast_data['Time'].values[p]), \"%H:%M:%S\").time()\n",
    "            forecast_data['DateTime'][p] = str(datetime.datetime.combine(forecast_data_date,forecast_data_time))\n",
    "    \n",
    "        #print('forecast_data',forecast_data)\n",
    "        current_date = np.array([[],[],[]]).reshape(-1,3)\n",
    "        for p in range(output_cycle*daily_data_points):\n",
    "            current_date_forecast = (datetime.datetime.strptime(str(last_date_input), \"%Y-%m-%d\") + datetime.timedelta(days=int(p/daily_data_points) + 1)).date()\n",
    "            current_time_forecast = datetime.datetime.strptime(str(forecast_data['Time'].values[p]), \"%H:%M:%S\").time()\n",
    "            current_datetime_forecast = datetime.datetime.combine(current_date_forecast,current_time_forecast)\n",
    "            current_date = np.concatenate((current_date, np.array([str(current_date_forecast),\n",
    "                                                                    str(current_time_forecast),\n",
    "                                                                    str(current_datetime_forecast)]).reshape(3,-1).T))\n",
    "        current_date = pd.DataFrame(current_date, columns = ['Date','Time','DateTime'])\n",
    "        #print('current_data',current_date)            \n",
    "        forecast_data = forecast_data.merge(current_date, how = 'outer', left_on = 'DateTime', right_on = 'DateTime')\n",
    "        #print('forecast_data_merged_first',forecast_data)\n",
    "        forecast_data = forecast_data[~np.isnan(forecast_data['Temp'].values)]\n",
    "        forecast_data = forecast_data[~pd.isnull(forecast_data['Date_y'].values)]\n",
    "        #print('forecast_data_merged',forecast_data)\n",
    "        forecast_data_partial = forecast_data[['Date_y', 'Time_y', 'DateTime', 'Air Temp', 'Sol Rad', 'Temp']]\n",
    "        forecast_data_partial = forecast_data_partial.rename(columns={\"Date_y\": \"Date\", \"Time_y\": \"Time\"})\n",
    "    \n",
    "            #recursive forecasting\n",
    "        exogenous_forecast = pd.DataFrame(forecast_data_partial)\n",
    "        forecast_ext_temp = exogenous_forecast['Air Temp'] - np.mean(exogenous_forecast['Air Temp'])\n",
    "        forecast_solar = exogenous_forecast['Sol Rad'] - np.mean(exogenous_forecast['Sol Rad'])\n",
    "        forecast_ice = [0]*len(forecast_solar)\n",
    "        exogenous_all_var_forecast = np.concatenate((np.linspace(0,len(exogenous_forecast['Air Temp'])-1,num=len(exogenous_forecast['Air Temp']),dtype = np.uint8).reshape(-1,1),\n",
    "                                            np.array(forecast_ext_temp).reshape(-1,1)),axis = 1).reshape(len(exogenous_forecast['Air Temp']),-1)\n",
    "        exogenous_all_var_forecast = np.concatenate((exogenous_all_var_forecast, np.array(forecast_solar).reshape(-1,1)),axis = 1).reshape(len(exogenous_forecast['Sol Rad']),-1)\n",
    "        exogenous_all_var_forecast = np.concatenate((exogenous_all_var_forecast, np.array(forecast_ice).reshape(-1,1)),axis = 1).reshape(len(exogenous_forecast['Sol Rad']),-1)\n",
    "        forecast = model.predict(len(exogenous_forecast['Air Temp']), X = exogenous_all_var_forecast)\n",
    "        #print(forecast)\n",
    "        id_no = [id_s]*len(forecast)\n",
    "        id_s = id_s + 1\n",
    "        forecast_sARX = np.concatenate((forecast_sARX, np.array([forecast_data_partial['Date'].values, \n",
    "                                                               forecast_data_partial['Time'].values,\n",
    "                                                               forecast_data_partial['DateTime'].values,  \n",
    "                                                               forecast_data_partial['Air Temp'].values,         \n",
    "                                                               forecast_data_partial['Sol Rad'].values,\n",
    "                                                               forecast_data_partial['Temp'].values,\n",
    "                                                               forecast.values,\n",
    "                                                               np.array(id_no)]).reshape(8,-1).T))\n",
    "        #print(forecast_sARX)\n",
    "        plt.plot(range(len(forecast_data_partial['Temp'].values)), forecast_data_partial['Temp'].values, label = 'Actual')\n",
    "        plt.plot(range(len(forecast_data_partial['Temp'].values)), forecast, label = 'forecast')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    forecast_sARX = pd.DataFrame(forecast_sARX, columns = ['Date', 'Time', 'DateTime', 'Air Temp', 'Sol Rad',\n",
    "                                                        'Temp_Actual', 'sARX', 'id_no'])\n",
    "    forecast_sARX['sARX error_2'] = (forecast_sARX['Temp_Actual'] - forecast_sARX['sARX'])**2\n",
    "    return forecast_sARX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df0d4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_sARX = Seasonal_ARX_forecast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0432f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Holt_Winters_forecast():\n",
    "    forecast_HW = np.array([[],[],[],[],[],[],[],[]]).reshape(-1,8)\n",
    "    id_s = 0\n",
    "    for i in range(0,int(len(data)/daily_data_points)-input_cycle-output_cycle+1):\n",
    "        print(i)\n",
    "        d_in =  data[i*daily_data_points:(i+input_cycle+output_cycle)*daily_data_points]\n",
    "        data_in = d_in[0:input_cycle*daily_data_points]['Temp'] #input core temperature data\n",
    "        model = ExponentialSmoothing(data_in,\n",
    "                                     trend='add',\n",
    "                                     seasonal='add',\n",
    "                                     seasonal_periods = 24, \n",
    "                                     initialization_method=\"estimated\").fit(optimized = True)\n",
    "        last_date_input = d_in[0:input_cycle*daily_data_points]['Date'].values[-1]\n",
    "                \n",
    "        forecast_whole = np.array([[],[],[],[]]).reshape(-1,4)\n",
    "\n",
    "        forecast_data = d_in[input_cycle*daily_data_points:(input_cycle+output_cycle)*daily_data_points]\n",
    "        forecast_data = forecast_data.reset_index() \n",
    "        \n",
    "        for p in range(len(forecast_data)):\n",
    "            forecast_data_date = datetime.datetime.strptime(str(forecast_data['Date'].values[p]),  \"%Y-%m-%d\").date() \n",
    "            forecast_data_time = datetime.datetime.strptime(str(forecast_data['Time'].values[p]), \"%H:%M:%S\").time()\n",
    "            forecast_data['DateTime'][p] = str(datetime.datetime.combine(forecast_data_date,forecast_data_time))\n",
    "    \n",
    "        current_date = np.array([[],[],[]]).reshape(-1,3)\n",
    "        for p in range(output_cycle*daily_data_points):\n",
    "            current_date_forecast = (datetime.datetime.strptime(str(last_date_input), \"%Y-%m-%d\") + datetime.timedelta(days=int(p/daily_data_points) + 1)).date()\n",
    "            current_time_forecast = datetime.datetime.strptime(str(forecast_data['Time'].values[p]), \"%H:%M:%S\").time()\n",
    "            current_datetime_forecast = datetime.datetime.combine(current_date_forecast,current_time_forecast)\n",
    "            current_date = np.concatenate((current_date, np.array([str(current_date_forecast),\n",
    "                                                                    str(current_time_forecast),\n",
    "                                                                    str(current_datetime_forecast)]).reshape(3,-1).T))\n",
    "        current_date = pd.DataFrame(current_date, columns = ['Date','Time','DateTime'])           \n",
    "        forecast_data = forecast_data.merge(current_date, how = 'outer', left_on = 'DateTime', right_on = 'DateTime')\n",
    "        forecast_data = forecast_data[~np.isnan(forecast_data['Temp'].values)]\n",
    "        forecast_data = forecast_data[~pd.isnull(forecast_data['Date_y'].values)]\n",
    "        forecast_data_partial = forecast_data[['Date_y', 'Time_y', 'DateTime', 'Air Temp', 'Sol Rad', 'Temp']]\n",
    "        forecast_data_partial = forecast_data_partial.rename(columns={\"Date_y\": \"Date\", \"Time_y\": \"Time\"})\n",
    "        \n",
    "        forecast = model.forecast(len(forecast_data_partial))\n",
    "        id_no = [id_s]*len(forecast)\n",
    "        id_s = id_s + 1\n",
    "        forecast_HW = np.concatenate((forecast_HW, np.array([forecast_data_partial['Date'].values, \n",
    "                                                               forecast_data_partial['Time'].values,\n",
    "                                                               forecast_data_partial['DateTime'].values,  \n",
    "                                                               forecast_data_partial['Air Temp'].values,         \n",
    "                                                               forecast_data_partial['Sol Rad'].values,\n",
    "                                                               forecast_data_partial['Temp'].values,\n",
    "                                                               forecast.values,\n",
    "                                                               np.array(id_no)]).reshape(8,-1).T))    \n",
    "        \n",
    "        plt.plot(range(len(forecast_data_partial['Temp'])), forecast_data_partial['Temp'].values, label = 'Actual')\n",
    "        plt.plot(range(len(forecast_data_partial['Temp'])), forecast, label = 'forecast')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    forecast_HW = pd.DataFrame(forecast_HW, columns = ['Date', 'Time', 'DateTime', 'Air Temp', 'Sol Rad',\n",
    "                                                        'Temp_Actual', 'HW', 'id_no'])\n",
    "    forecast_HW['HW error_2'] = (forecast_HW['Temp_Actual'] - forecast_HW['HW'])**2\n",
    "    return forecast_HW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3036db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "forecast_HW = Holt_Winters_forecast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b5417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lmfit import minimize, Parameters\n",
    "import scipy.integrate as scint\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4564d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bee_eq(y, t, w1,w2, env_temp, h, theta_ideal):\n",
    "    hive_temp = y\n",
    "    M = -h*(w1*w2*(1-np.exp(-hive_temp+theta_ideal)) / (w2+w1*np.exp(-hive_temp+theta_ideal)))\n",
    "    W = 2*(-hive_temp + env_temp) \n",
    "    dydt = M + W \n",
    "    return dydt\n",
    "\n",
    "def run_bee_eq(t, a, w1,w2, env_temp, h, theta_ideal):\n",
    "    sol = scint.odeint(bee_eq, a, t, args=(w1,w2, env_temp, h, theta_ideal), \n",
    "                                           col_deriv = True, rtol = 10e-3, atol = 10e-3)\n",
    "    theta_t = sol[-1,:]\n",
    "    return theta_t    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc5a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual(ps, ts, data, l, argv):\n",
    "    d = pd.DataFrame(data).groupby(data['Date'])\n",
    "    model = []\n",
    "    k = 0\n",
    "    alpha  = 1\n",
    "    r_c = 81 #ps['w1'].value\n",
    "    r_h = 220 #ps['w2'].value\n",
    "    h_ = [1]\n",
    "    return_value = []\n",
    "    for m,n in d:\n",
    "        h = ps['h_'+str(k)].value #health factor per day\n",
    "        theta_ideal = ps['theta_'+str(k)].value + 273.15 #theta_ideal per day\n",
    "        t_max = len(n[argv[1]])-1\n",
    "        t = np.linspace(0,t_max, num = t_max+1)\n",
    "        environment_temp = n[argv[1]].values + 273.15 #hourly environment temperature -> kelvin\n",
    "        \n",
    "        a = [1]*len(environment_temp)\n",
    "        \n",
    "        fitted = run_bee_eq(t, a, r_c, r_h, environment_temp, h, theta_ideal)\n",
    "        model = np.concatenate((model, fitted - 273.15))\n",
    "        try:\n",
    "            h_.append(abs(h - ps['h_'+str(k-1)].value))\n",
    "        except:\n",
    "            h_.append(abs(h_[k] - h))\n",
    "        k = k+1\n",
    "    return_value = np.concatenate((return_value, (model - data[argv[3]]).ravel()))\n",
    "    return_value = np.concatenate((return_value, l*np.array(h_[2:]).ravel()))\n",
    "    return return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bf469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(*argv):\n",
    "    data = pd.read_csv(argv[0])\n",
    "    try:\n",
    "        for i in range(len(data)):\n",
    "            current_date = (datetime.datetime.strptime(str(data['Date'].values[i]), \"%m/%d/%Y\")).date()\n",
    "            current_time = datetime.datetime.strptime(str(data['Time'].values[i]), \"%H:%M:%S\").time()\n",
    "            current_datetime = datetime.datetime.combine(current_date,current_time)\n",
    "            data['DateTime'][i] = datetime.datetime.strptime(str(current_datetime), \"%Y-%m-%d %H:%M:%S\")\n",
    "            data['Date'][i] = data['DateTime'][i].date()\n",
    "            data['Time'][i] = data['DateTime'][i].time()\n",
    "    except:\n",
    "        pass\n",
    "    d = pd.DataFrame(data).groupby([data['Date']])\n",
    "    h_max = 1\n",
    "    l = 96/h_max\n",
    "\n",
    "    forecast_EBVplus = np.array([[],[],[],[],[],[],[],[]]).reshape(-1,8)\n",
    "    id_s = 0\n",
    "    for i in range(0,int(len(data)/daily_data_points)-input_cycle-output_cycle+1):\n",
    "        print(i)\n",
    "        d_in =  data[i*daily_data_points:(i+input_cycle+output_cycle)*daily_data_points] #whole dataset -> input_cycle+output_cycle\n",
    "        data_in = d_in[0:input_cycle*daily_data_points]['Temp'] #input core temperature data\n",
    "        exogenous_train = pd.DataFrame(d_in[0:len(data_in)]) #input exogenous data\n",
    "        data_input = d_in[0:daily_data_points*input_cycle]\n",
    "        data_temp_input = d_in[argv[3]][0:daily_data_points*input_cycle] #7 days hive core temperature for forecasting -> celcius\n",
    "        data_ext_input = d_in[argv[1]][0:daily_data_points*input_cycle] #7 days environment temperature for forecasting -> celcius\n",
    "\n",
    "        params = Parameters()\n",
    "        for j in range(7):\n",
    "            params.add('h_'+str(j), value = 0.5, min = 0.2, max = h_max)\n",
    "            params.add('theta_'+str(j), value = 35, min = 33, max = 38)   \n",
    "        t_max = len(data_ext_input)-1\n",
    "        t = np.linspace(0,t_max, num = t_max+1)\n",
    "        result = minimize(residual, params, args=(t,data_input, l, argv),\n",
    "                          method='leastsq',nan_policy='omit',max_nfev = 300)\n",
    "        sig_min = data_temp_input + result.residual[:len(data_temp_input)].reshape(data_temp_input.shape)\n",
    "        \n",
    "\n",
    "        param_min_h,param_min_theta = [], []\n",
    "        for m in range(input_cycle):\n",
    "            param_min_h.append(result.params['h_'+str(m)].value)\n",
    "            param_min_theta.append(result.params['theta_'+str(m)].value)\n",
    "            \n",
    "        ##one day ahead forecast \n",
    "        forecast_h = param_min_h[-1]\n",
    "        forecast_theta = param_min_theta[-1]\n",
    "\n",
    "        h = forecast_h\n",
    "        theta_ideal = forecast_theta + 273.15\n",
    "        #theta_ideal = result.params['theta_'+str(6)].value + 273.15\n",
    "        \n",
    "        last_date_input = d_in[0:input_cycle*daily_data_points]['Date'].values[-1]\n",
    "        forecast_data = d_in[input_cycle*daily_data_points:(input_cycle+output_cycle)*daily_data_points]\n",
    "        forecast_data = forecast_data.reset_index() \n",
    "        \n",
    "        for p in range(len(forecast_data)):\n",
    "            forecast_data_date = datetime.datetime.strptime(str(forecast_data['Date'].values[p]),  \"%Y-%m-%d\").date() \n",
    "            forecast_data_time = datetime.datetime.strptime(str(forecast_data['Time'].values[p]), \"%H:%M:%S\").time()\n",
    "            forecast_data['DateTime'][p] = str(datetime.datetime.combine(forecast_data_date,forecast_data_time))\n",
    "    \n",
    "        #print('forecast_data',forecast_data)\n",
    "        current_date = np.array([[],[],[]]).reshape(-1,3)\n",
    "        for p in range(output_cycle*daily_data_points):\n",
    "            current_date_forecast = (datetime.datetime.strptime(str(last_date_input), \"%Y-%m-%d\") + datetime.timedelta(days=int(p/daily_data_points) + 1)).date()\n",
    "            current_time_forecast = datetime.datetime.strptime(str(forecast_data['Time'].values[p]), \"%H:%M:%S\").time()\n",
    "            current_datetime_forecast = datetime.datetime.combine(current_date_forecast,current_time_forecast)\n",
    "            current_date = np.concatenate((current_date, np.array([str(current_date_forecast),\n",
    "                                                                    str(current_time_forecast),\n",
    "                                                                    str(current_datetime_forecast)]).reshape(3,-1).T))\n",
    "        current_date = pd.DataFrame(current_date, columns = ['Date','Time','DateTime'])\n",
    "        #print('current_data',current_date)            \n",
    "        forecast_data = forecast_data.merge(current_date, how = 'outer', left_on = 'DateTime', right_on = 'DateTime')\n",
    "        #print('forecast_data_merged_first',forecast_data)\n",
    "        forecast_data = forecast_data[~np.isnan(forecast_data['Temp'].values)]\n",
    "        forecast_data = forecast_data[~pd.isnull(forecast_data['Date_y'].values)]\n",
    "        #print('forecast_data_merged',forecast_data)\n",
    "        forecast_data_partial = forecast_data[['Date_y', 'Time_y', 'DateTime', 'Air Temp', 'Sol Rad', 'Temp']]\n",
    "        forecast_data_partial = forecast_data_partial.rename(columns={\"Date_y\": \"Date\", \"Time_y\": \"Time\"})\n",
    "        \n",
    "        t = np.linspace(0, len(forecast_data_partial)-1, num = len(forecast_data_partial)) #forecast hourly\n",
    "        a = [1]*len(t)\n",
    "        r_c = 81 #ps['w1'].value\n",
    "        r_h = 220 #ps['w2'].value\n",
    "        \n",
    "        env_temp_future = forecast_data_partial[argv[1]] + 273.15\n",
    "        solar_rad_future = forecast_data_partial[argv[2]]\n",
    "        hive_temp_future = forecast_data_partial[argv[3]]\n",
    "        \n",
    "        forecasted = run_bee_eq(t, a, r_c, r_h, env_temp_future, h, theta_ideal) - 273.15\n",
    "        print(len(forecasted))\n",
    "        id_no = [id_s]*len(forecasted)\n",
    "        id_s = id_s + 1\n",
    "        forecast_EBVplus = np.concatenate((forecast_EBVplus, np.array([forecast_data_partial['Date'].values, \n",
    "                                                               forecast_data_partial['Time'].values,\n",
    "                                                               forecast_data_partial['DateTime'].values,  \n",
    "                                                               forecast_data_partial['Air Temp'].values,         \n",
    "                                                               forecast_data_partial['Sol Rad'].values,\n",
    "                                                               forecast_data_partial['Temp'].values,\n",
    "                                                               np.array(forecasted),\n",
    "                                                               np.array(id_no)]).reshape(8,-1).T))\n",
    "        \n",
    "        plt.figure(figsize = (10,4), dpi = 200)\n",
    "        plt.plot(hive_temp_future, label = 'Hive Core Temperature', color = 'blue')\n",
    "        plt.plot(forecasted, label = 'Forecasted Core Temp', color = 'red') \n",
    "        plt.xlabel('Samples per hour')\n",
    "        plt.ylabel('Temperature in celcius')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    forecast_EBVplus = pd.DataFrame(forecast_EBVplus, columns = ['Date', 'Time', 'DateTime', 'Air Temp', 'Sol Rad',\n",
    "                                                        'Temp_Actual', 'EBV+', 'id_no'])\n",
    "    forecast_EBVplus['EBV+ error_2'] = (forecast_EBVplus['Temp_Actual'] - forecast_EBVplus['EBV+'])**2\n",
    "    \n",
    "    return forecast_EBVplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac89f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    filename = 'C:\\Bee Temp Data\\C294_w_Env.csv'\n",
    "    environment_temperature = 'Air Temp'\n",
    "    solar_radiation = 'Sol Rad'\n",
    "    hive_temperature = 'Temp'\n",
    "    forecast_EBVplus = main(filename, environment_temperature, solar_radiation, hive_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d3218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bee_eq(y, t, w1,w2, env_temp,h, solar, k_W, k_A_W, k_hive, eta_W, \n",
    "           eta_A_W, eta_B_W, theta_ideal, k_c, P_C):\n",
    "    hive_temp = y\n",
    "    M = -h*(w1*w2*(1-np.exp(-hive_temp+theta_ideal)) / (w2+w1*np.exp(-hive_temp+theta_ideal)))\n",
    "    W = 4*(k_W + k_c + k_hive)*(-hive_temp + env_temp) + 4*eta_W*solar \n",
    "    A_W = (k_A_W+k_hive)*(-hive_temp + env_temp) + eta_A_W*solar\n",
    "    B_W = (k_W+k_hive)*(-hive_temp + env_temp) + eta_B_W*solar\n",
    "    dydt = M + W + A_W + B_W - P_C\n",
    "    return dydt\n",
    "\n",
    "def run_bee_eq(t, a, w1,w2, env_temp,h, solar, k_W, k_A_W, k_hive, eta_W, eta_A_W, eta_B_W, theta_ideal, k_c, P_C):\n",
    "    sol = scint.odeint(bee_eq, a, t, args=(w1,w2, env_temp,h, solar, k_W, k_A_W, k_hive, \n",
    "                                           eta_W, eta_A_W, eta_B_W, theta_ideal, k_c, P_C), \n",
    "                                           col_deriv = True, rtol = 10e-3, atol = 10e-3)\n",
    "                                           #hmin = 0.001) #w' and 'amplitude_temp_ext'\n",
    "    theta_t = sol[-1,:]\n",
    "    return theta_t  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3155ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual(ps, ts, data, l, argv, k_W, k_A_W, k_hive, eta_W, eta_A_W, eta_B_W, k_c, P_C):\n",
    "    d = pd.DataFrame(data).groupby(data['Date'])\n",
    "    model = []\n",
    "    k = 0\n",
    "    alpha  = 1\n",
    "    r_c = 124 #ps['w1'].value\n",
    "    r_h = 428 #ps['w2'].value\n",
    "    h_ = [1]\n",
    "    return_value = []\n",
    "    for m,n in d:\n",
    "        h = ps['h_'+str(k)].value #health factor per day\n",
    "        theta_ideal = ps['theta_'+str(k)].value + 273.15 #theta_ideal per day\n",
    "        t_max = len(n[argv[1]])-1\n",
    "        t = np.linspace(0,t_max, num = t_max+1)\n",
    "        environment_temp = n[argv[1]].values + 273.15 #hourly environment temperature -> kelvin\n",
    "        solar_rad = n[argv[2]].values #hourly solar radiation -> kelvin\n",
    "        P_C = n['P'].values\n",
    "        \n",
    "        a = [1]*len(environment_temp)\n",
    "        \n",
    "        fitted = run_bee_eq(t, a, r_c, r_h, environment_temp, h, solar_rad, k_W, k_A_W, \n",
    "                            k_hive, eta_W, eta_A_W, eta_B_W, theta_ideal, k_c, P_C)\n",
    "        model = np.concatenate((model, fitted - 273.15))\n",
    "        try:\n",
    "            h_.append(abs(h - ps['h_'+str(k-1)].value))\n",
    "        except:\n",
    "            h_.append(abs(h_[k] - h))\n",
    "        k = k+1\n",
    "    return_value = np.concatenate((return_value, (model - data[argv[3]]).ravel()))\n",
    "    return_value = np.concatenate((return_value, l*np.array(h_[2:]).ravel()))\n",
    "    #print(np.mean(abs((model - data[argv[3]]).ravel())))\n",
    "    return return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3772e584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(*argv):\n",
    "    data = pd.read_csv(argv[0])\n",
    "    try:\n",
    "        for i in range(len(data)):\n",
    "            current_date = (datetime.datetime.strptime(str(data['Date'].values[i]), \"%m/%d/%Y\")).date()\n",
    "            current_time = datetime.datetime.strptime(str(data['Time'].values[i]), \"%H:%M:%S\").time()\n",
    "            current_datetime = datetime.datetime.combine(current_date,current_time)\n",
    "            data['DateTime'][i] = datetime.datetime.strptime(str(current_datetime), \"%Y-%m-%d %H:%M:%S\")\n",
    "            data['Date'][i] = data['DateTime'][i].date()\n",
    "            data['Time'][i] = data['DateTime'][i].time()\n",
    "    except:\n",
    "        pass\n",
    "    d = pd.DataFrame(data).groupby([data['Date']])\n",
    "    k_W = 0.29 #thermal conductivity of wood -> per hour\n",
    "    eta_W = 0.0085*k_W #heat absorption coeff of wood\n",
    "    k_A_W = k_W #thermal conductivity of top surface (wood + aluminum plate) -> per hour\n",
    "    eta_A_W = eta_W #heat absorption coeff of top surface\n",
    "    eta_B_W = eta_W #heat absorption coeff of bottom surface\n",
    "    k_hive = 0.8\n",
    "    k_c = 0\n",
    "    h_max = 1\n",
    "    l = 96/h_max\n",
    "\n",
    "    forecast_ABK = np.array([[],[],[],[],[],[],[],[]]).reshape(-1,8)\n",
    "    id_s = 0\n",
    "    for i in range(0,int(len(data)/daily_data_points)-input_cycle-output_cycle+1):\n",
    "        print(i)\n",
    "        d_in =  data[i*daily_data_points:(i+input_cycle+output_cycle)*daily_data_points] #whole dataset -> input_cycle+output_cycle\n",
    "        data_in = d_in[0:input_cycle*daily_data_points]['Temp'] #input core temperature data\n",
    "        exogenous_train = pd.DataFrame(d_in[0:len(data_in)]) #input exogenous data\n",
    "        data_input = d_in[0:daily_data_points*input_cycle]\n",
    "        data_temp_input = d_in[argv[3]][0:daily_data_points*input_cycle] #7 days hive core temperature for forecasting -> celcius\n",
    "        data_ext_input = d_in[argv[1]][0:daily_data_points*input_cycle] #7 days environment temperature for forecasting -> celcius\n",
    "        P_C = data_input['P'][0:24*7]\n",
    "        params = Parameters()\n",
    "        for j in range(7):\n",
    "            params.add('h_'+str(j), value = 0.5, min = 0.2, max = h_max)\n",
    "            params.add('theta_'+str(j), value = 35, min = 33, max = 38)   \n",
    "        t_max = len(data_ext_input)-1\n",
    "        t = np.linspace(0,t_max, num = t_max+1)\n",
    "        result = minimize(residual, params, args=(t,data_input, l, argv, k_W, k_A_W, \n",
    "                                                  k_hive, eta_W, eta_A_W, eta_B_W, k_c, P_C),\n",
    "                          method='leastsq',nan_policy='omit',max_nfev = 300)\n",
    "        sig_min = data_temp_input + result.residual[:len(data_temp_input)].reshape(data_temp_input.shape)\n",
    "        \n",
    "\n",
    "        param_min_h,param_min_theta = [], []\n",
    "        for m in range(input_cycle):\n",
    "            param_min_h.append(result.params['h_'+str(m)].value)\n",
    "            param_min_theta.append(result.params['theta_'+str(m)].value)\n",
    "            \n",
    "        ##one day ahead forecast \n",
    "        forecast_h = param_min_h[-1]\n",
    "        forecast_theta = param_min_theta[-1]\n",
    "\n",
    "        h = forecast_h\n",
    "        theta_ideal = forecast_theta + 273.15\n",
    "        #theta_ideal = result.params['theta_'+str(6)].value + 273.15\n",
    "        \n",
    "        last_date_input = d_in[0:input_cycle*daily_data_points]['Date'].values[-1]\n",
    "        forecast_data = d_in[input_cycle*daily_data_points:(input_cycle+output_cycle)*daily_data_points]\n",
    "        forecast_data = forecast_data.reset_index() \n",
    "        \n",
    "        for p in range(len(forecast_data)):\n",
    "            forecast_data_date = datetime.datetime.strptime(str(forecast_data['Date'].values[p]),  \"%Y-%m-%d\").date() \n",
    "            forecast_data_time = datetime.datetime.strptime(str(forecast_data['Time'].values[p]), \"%H:%M:%S\").time()\n",
    "            forecast_data['DateTime'][p] = str(datetime.datetime.combine(forecast_data_date,forecast_data_time))\n",
    "    \n",
    "        #print('forecast_data',forecast_data)\n",
    "        current_date = np.array([[],[],[]]).reshape(-1,3)\n",
    "        for p in range(output_cycle*daily_data_points):\n",
    "            current_date_forecast = (datetime.datetime.strptime(str(last_date_input), \"%Y-%m-%d\") + datetime.timedelta(days=int(p/daily_data_points) + 1)).date()\n",
    "            current_time_forecast = datetime.datetime.strptime(str(forecast_data['Time'].values[p]), \"%H:%M:%S\").time()\n",
    "            current_datetime_forecast = datetime.datetime.combine(current_date_forecast,current_time_forecast)\n",
    "            current_date = np.concatenate((current_date, np.array([str(current_date_forecast),\n",
    "                                                                    str(current_time_forecast),\n",
    "                                                                    str(current_datetime_forecast)]).reshape(3,-1).T))\n",
    "        current_date = pd.DataFrame(current_date, columns = ['Date','Time','DateTime'])\n",
    "        #print('current_data',current_date)            \n",
    "        forecast_data = forecast_data.merge(current_date, how = 'outer', left_on = 'DateTime', right_on = 'DateTime')\n",
    "        #print('forecast_data_merged_first',forecast_data)\n",
    "        forecast_data = forecast_data[~np.isnan(forecast_data['Temp'].values)]\n",
    "        forecast_data = forecast_data[~pd.isnull(forecast_data['Date_y'].values)]\n",
    "        #print('forecast_data_merged',forecast_data)\n",
    "        forecast_data_partial = forecast_data[['Date_y', 'Time_y', 'DateTime', 'Air Temp', 'Sol Rad', 'Temp']]\n",
    "        forecast_data_partial = forecast_data_partial.rename(columns={\"Date_y\": \"Date\", \"Time_y\": \"Time\"})\n",
    "        \n",
    "        t = np.linspace(0, len(forecast_data_partial)-1, num = len(forecast_data_partial)) #forecast hourly\n",
    "        a = [1]*len(t)\n",
    "        r_c = 124#ps['w1'].value\n",
    "        r_h = 428 #['w2'].value\n",
    "        \n",
    "        env_temp_future = forecast_data_partial[argv[1]] + 273.15\n",
    "        solar_rad_future = forecast_data_partial[argv[2]]\n",
    "        hive_temp_future = forecast_data_partial[argv[3]]\n",
    "        \n",
    "        forecasted = run_bee_eq(t, a, r_c, r_h, env_temp_future, h, \n",
    "                                         solar_rad_future, \n",
    "                                         k_W, k_A_W, k_hive, eta_W, eta_A_W, eta_B_W, theta_ideal, 0, 0) - 273.15\n",
    "        id_no = [id_s]*len(forecasted)\n",
    "        id_s = id_s + 1\n",
    "        forecast_ABK = np.concatenate((forecast_ABK np.array([forecast_data_partial['Date'].values, \n",
    "                                                               forecast_data_partial['Time'].values,\n",
    "                                                               forecast_data_partial['DateTime'].values,  \n",
    "                                                               forecast_data_partial['Air Temp'].values,         \n",
    "                                                               forecast_data_partial['Sol Rad'].values,\n",
    "                                                               forecast_data_partial['Temp'].values,\n",
    "                                                               np.array(forecasted),\n",
    "                                                               np.array(id_no)]).reshape(8,-1).T))\n",
    "        \n",
    "        plt.figure(figsize = (10,4), dpi = 200)\n",
    "        plt.plot(hive_temp_future, label = 'Hive Core Temperature', color = 'blue')\n",
    "        plt.plot(forecasted, label = 'Forecasted Core Temp', color = 'red') \n",
    "        plt.xlabel('Samples per hour')\n",
    "        plt.ylabel('Temperature in celcius')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    forecast_ABK = pd.DataFrame(forecast_ABK, columns = ['Date', 'Time', 'DateTime', 'Air Temp', 'Sol Rad',\n",
    "                                                        'Temp_Actual', 'ABK', 'id_no'])\n",
    "    forecast_ABK['ABK error_2'] = (forecast_ABK['Temp_Actual'] - forecast_ABK['ABK'])**2\n",
    "    \n",
    "    return forecast_ABK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0595252",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    filename = 'C:\\Bee Temp Data\\C294_w_Env.csv'\n",
    "    environment_temperature = 'Air Temp'\n",
    "    solar_radiation = 'Sol Rad'\n",
    "    hive_temperature = 'Temp'\n",
    "    forecast_EBVC = main(filename, environment_temperature, solar_radiation, hive_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0cc6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_forecast = forecast_ARX.merge(forecast_sARX, how='outer', left_on = ['id_no','DateTime'], right_on = ['id_no','DateTime'])\n",
    "all_forecast = all_forecast.merge(forecast_HW, how = 'outer', left_on = ['id_no','DateTime'], right_on = ['id_no','DateTime'])\n",
    "all_forecast = all_forecast[['Date_x','Time_x','DateTime','id_no','Air Temp_x','Sol Rad_x','Temp_Actual_x','ARX',\n",
    "                              'ARX error_2','sARX', 'sARX error_2','HW', 'HW error_2']]\n",
    "all_forecast = all_forecast.merge(forecast_EBVplus, how = 'outer', left_on = ['id_no','DateTime'], right_on = ['id_no','DateTime'])\n",
    "all_forecast = all_forecast[['Date_x','Time_x','DateTime','id_no','Air Temp_x','Sol Rad_x','Temp_Actual_x','ARX',\n",
    "                              'ARX error_2','sARX', 'sARX error_2','HW', 'HW error_2', 'EBV+', 'EBV+ error_2']]\n",
    "all_forecast = all_forecast.merge(forecast_ABK, how = 'outer', left_on = ['id_no','DateTime'], right_on = ['id_no','DateTime'])\n",
    "forecasted_all = all_forecast[['Date_x','Time_x','DateTime','id_no','Air Temp_x','Sol Rad_x','Temp_Actual_x','ARX',\n",
    "                              'ARX error_2','sARX', 'sARX error_2','HW', 'HW error_2', 'EBV+', 'EBV+ error_2',\n",
    "                               'ABK', 'ABK error_2', ]]\n",
    "forecasted_all = forecasted_all.rename(columns={\"Date_x\": \"Date\", \"Time_x\": \"Time\", \"Air Temp_x\": \"Air Temp\",\n",
    "                                               \"Sol Rad_x\":\"Sol Rad\", \"Temp_Actual_x\":\"Temp_Actual\"})\n",
    "forecasted_all.to_csv('C:\\Bee Temp Data\\ABK_Baseline_Forecast_294.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd803d22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
